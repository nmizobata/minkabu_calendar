{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# みん株 経済指標スケジュールをWebスクレイピングしGoogle Calendarに反映する\n",
    "# https://fx.minkabu.jp/indicators\n",
    "# googleカレンダーのプログラムに関するメモ https://share.evernote.com/note/9195e429-ef9a-785a-7259-4eec3c5c10b8\n",
    "# \n",
    "# 20230113 ver0.1 みんかぶ株式指標スケジュールからデータを抜き出すエンジン開発\n",
    "# 20230114 ver1.0 定期実行可能なように、重複の回避、差分のみの追加機能を実装\n",
    "# 20230315 ver1.1 時間部分に\"未定\"と記入されている場合のエラー発生を回避\n",
    "# 20230724 ver1.2 プライオリティのフォーマットが変更されあため対応\n",
    "# 20240911 ver1.3 バグ修正-UTCフォーマット, 「米国休場」でのエラー他\n",
    "# 20241224 ver1.4 バグ修正-(def get_googlecalendar()) google calendarから取得データが無い場合に発生するエラーを修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install google-api-python-client google-auth\n",
    "#!pip install google-auth-httplib2\n",
    "#!pip install google-auth-oauthlib\n",
    "#!pip install investpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b54a687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# investpyによる経済指標情報の入手\n",
    "\n",
    "#import investpy\n",
    "#import pandas as pd\n",
    "#economic_data = investpy.economic_calendar(time_zone= \"GMT +9:00\", time_filter='time_only', countries=None,importances=[\"high\"],from_date='01/1/2023', to_date='31/12/2023')\n",
    "#economic_data = economic_data[economic_data['importance']=='high']\n",
    "#euro_data = economic_data[economic_data[\"zone\"] == \"euro zone\"]\n",
    "#japan_data = economic_data[economic_data[\"zone\"] == \"japan\"]\n",
    "#usa_data = economic_data[economic_data[\"zone\"] == \"united states\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b9f48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# みんかぶの将来データは、翌月末まで。\n",
    "# みんかぶから経済指標スケジュール情報を明日～翌月末(最長60日間)分を取得。翌々月以降は取得しない。\n",
    "def get_economiy_indicators_60days():\n",
    "    import datetime as dt\n",
    "    import pandas as pd\n",
    "\n",
    "    date_index = pd.date_range(dt.datetime.now()+dt.timedelta(days=1), periods=60, freq=\"D\")\n",
    "    thisMonth = dt.datetime.now().month\n",
    "#    date_index = pd.date_range(dt.datetime.now(), periods=60, freq=\"D\")\n",
    "    df=pd.DataFrame()\n",
    "    for date in date_index:\n",
    "        if date.month > thisMonth+1:\n",
    "            continue\n",
    "        print('{}のデータを取り込んでいます'.format(date.strftime('%Y%m%d')))\n",
    "        df_temp=get_economy_indicators_from_minkabu(date)\n",
    "        df=pd.concat([df,df_temp])\n",
    "\n",
    "    # date, country, event_shortが同一のデータを消去\n",
    "    df.drop_duplicates(subset=['date','country','event_short'],inplace=True)\n",
    "    df=df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# 特定の日付のみんかぶWebスクレイピングによる経済指標データの入手\n",
    "# date: 日付(datetime形式)\n",
    "# 返値: pandas dataframe: date,time,importance,currency,country,event,event_short\n",
    "# 注意！ みんかぶは日付が存在するデータを超えて日付を指定した場合、エラーではなく最終日のデータを表示。そのためその日付としてデータを取り込むエラーが起きる。修正が必要。\n",
    "def get_economy_indicators_from_minkabu(date):\n",
    "    import pandas as pd\n",
    "    import requests\n",
    "    import bs4\n",
    "    import re\n",
    "\n",
    "    # みんかぶ経済指標スケジュールサイト\n",
    "    date_text=date.strftime('%Y-%m-%d')\n",
    "    URL= 'https://fx.minkabu.jp/indicators?date='+date_text\n",
    "\n",
    "    res = requests.get(URL)\n",
    "    soup=bs4.BeautifulSoup(res.content,'lxml',from_encoding='utf-8')\n",
    "    listdata=str(soup.select('body > div > main > section > div > table:nth-child(3)')) \n",
    "#    print(listdata)\n",
    "#    listdataのファイルへの書き出し(デバッグ用)\n",
    "#    with open(r\"C:\\Users\\blues\\Desktop\"+\"/\"+\"listdata.txt\",mode=\"w\") as f:\n",
    "#        f.write(listdata)\n",
    "\n",
    "    # 時刻データ\n",
    "    re_command=re.compile(r'(?:>)?([\\d]+?:[\\d]+?|－|未定)(?:<br/>|</span>|</td>)')\n",
    "    time_data=re_command.findall(listdata)\n",
    "    time_data=['0:0' if time == \"未定\" else time for time in time_data]\n",
    "#    print('time_data:{}'.format(time_data))\n",
    "\n",
    "    # 日付データ\n",
    "    date_data=[date.strftime('%Y/%m/%d')]*len(time_data)\n",
    "#    print('date_data:{}'.format(date_data))\n",
    "    \n",
    "    # イベントデータ(フル表示)\n",
    "    re_command2=re.compile(r'(?:nowrap\">|fbd\">)(.+?)(?:</p>)')\n",
    "    title_data=re_command2.findall(listdata)\n",
    "    title=[]\n",
    "    title_num=0\n",
    "    for i in range(len(title_data)):\n",
    "        # print(\"title_data:{}\".format(title_data[i]))\n",
    "        if title_data[i][0]=='[':\n",
    "            title[title_num-1]=title_data[i-1]+' '+title_data[i]\n",
    "        else:\n",
    "            if '・' in title_data[i]:\n",
    "                title_data[i]=title_data[i].split('・',1)[1]\n",
    "            else:\n",
    "                continue\n",
    "            title.append(title_data[i])\n",
    "            title_num=title_num+1\n",
    "    \n",
    "    # イベントデータ(短縮表示)\n",
    "    short_title=[item.split()[0] for item in title]    \n",
    "    \n",
    "    # 国名\n",
    "#    re_command=re.compile(r'(?:img alt=\")(.+?|－)(?:\" class=\"mt3)')\n",
    "    re_command=re.compile(r'(?:grow fbd\">)(.+?|－)(?:・)')\n",
    "    country_data=re_command.findall(listdata)\n",
    "    # print(\"country_data:{}\".format(country_data))\n",
    "\n",
    "    # 関連する通貨名\n",
    "    currency_dic={  'アメリカ':'USD',\n",
    "                    'ユーロ':'EUR',\n",
    "                    'アンドラ':'EUR',\n",
    "                    'オーストリア':'EUR',\n",
    "                    'ベルギー':'EUR',\n",
    "                    'キプロス':'EUR',\n",
    "                    'ドイツ':'EUR',\n",
    "                    'スペイン':'EUR',\n",
    "                    'エストニア':'EUR',\n",
    "                    'フィンランド':'EUR',\n",
    "                    'フランス':'EUR',\n",
    "                    'ギリシャ':'EUR',\n",
    "                    'クロアチア':'EUR',\n",
    "                    'アイルランド':'EUR',\n",
    "                    'イタリア':'EUR',\n",
    "                    'ラトビア':'EUR',\n",
    "                    'リトアニア':'EUR',\n",
    "                    'ルクセンブルク':'EUR',\n",
    "                    'モナコ':'EUR',\n",
    "                    'マルタ':'EUR',\n",
    "                    'オランダ':'EUR',\n",
    "                    'ポルトガル':'EUR',\n",
    "                    'サンマリノ':'EUR',\n",
    "                    'スロバキア':'EUR',\n",
    "                    'スロベニア':'EUR',\n",
    "                    'バチカン':'EUR',\n",
    "                    '英国':'GBP',\n",
    "                    'オーストラリア':'AUD',\n",
    "                    'ニュージーランド':'NZD',\n",
    "                    'カナダ':'CAD',\n",
    "                    'スイス':'CHF',\n",
    "                    '日本':'JPY'}\n",
    "    currency=[]\n",
    "    for country in country_data:\n",
    "        if country in currency_dic:\n",
    "            currency.append(currency_dic[country])\n",
    "        else:\n",
    "            currency.append('-')\n",
    "\n",
    "    # 重要度 i-starの文字列の中のstar-fillの数を数える\n",
    "#    re_command3=re.compile(r'(?:img alt=\")(.+?)(?:\" class=\"i-star\")')\n",
    "    re_command3=re.compile(r'<span><img class=\"i-star\".+.svg\"/></span>')\n",
    "    priority_string_list=re_command3.findall(listdata)\n",
    "#    print('priority_data:{}'.format(priority_string_list))\n",
    "    priority=[]\n",
    "#    for i in range(int(len(priority_data)/5)):\n",
    "#        priority_level=0\n",
    "#        for j in range(5):\n",
    "#            if priority_data[i*5+j]=='Star fill':\n",
    "#                priority_level=priority_level+1\n",
    "    for priority_string in priority_string_list:\n",
    "        priority_level=priority_string.count('star-fill')\n",
    "        priority.append(priority_level)\n",
    "#        print('stars:{}'.format(priority_level))\n",
    "\n",
    "    # DataFrame化\n",
    "#    print('date:{}, time:{}, inportance:{},currency:{}, country:{}, event:{}, event_short:{}'.format(date_data, time_data, priority, currency, country_data, title,short_title))\n",
    "    # print(\"date:{}, {}\".format(date_data,len(date_data)))\n",
    "    # print(\"time:{},{}\".format(time_data,len(time_data)))\n",
    "    # print(\"importance:{},{}\".format(priority,len(priority)))\n",
    "    # print(\"currency:{},{}\".format(currency,len(currency)))\n",
    "    # print(\"country:{},{}\".format(country_data,len(country_data)))\n",
    "    # print(\"event:{},{}\".format(title,len(title)))\n",
    "    # print(\"event_short:{},{}\".format(short_title,len(short_title)))\n",
    "\n",
    "    df = pd.DataFrame({'date':date_data,\n",
    "                       'time':time_data,\n",
    "                       'importance':priority,\n",
    "                       'currency':currency,\n",
    "                       'country':country_data,\n",
    "                       'event':title,\n",
    "                       'event_short':short_title})\n",
    "    # print(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bbbe5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 経済指標スケジュールデータと、google calendarのデータを比較して差分を返す\n",
    "# google calendar timeMinで指定できる時間のフォーマットは厳密。'2024-09-11T06:41:10.580216Z'に合わせること。\n",
    "def get_googlecalendar(calendar_id,service):\n",
    "    import datetime as dt\n",
    "    import pandas as pd\n",
    "    \n",
    "    # google calendar 経済指標データの取り込み\n",
    "    # now = dt.datetime.utcnow().isoformat() + 'Z'\n",
    "    previous_days = dt.timedelta(days=0)     # 何日さかのぼってデータを取得するか? 今は0日で処理。\n",
    "    now = \"T\".join(str(dt.datetime.now(dt.UTC)-previous_days).split(\" \"))[:-6]+\"Z\"\n",
    "    event_list = service.events().list(\n",
    "         calendarId=calendar_id, timeMin=now,\n",
    "         #maxResults=3, \n",
    "         singleEvents=True,\n",
    "         orderBy='startTime').execute()\n",
    "\n",
    "    events = event_list.get('items', [])\n",
    "    # print(events)\n",
    "    formatted_events = [\n",
    "        {\n",
    "        'start':event['start'].get('dateTime', event['start'].get('date')), # start time or day\n",
    "        'end':event['end'].get('dateTime', event['end'].get('date')), # end time or day\n",
    "        'event(currency)':event['summary'],\n",
    "        'event_id':event['id']} \n",
    "                        for event in events]\n",
    "    # print(formatted_events)\n",
    "    df_googlecalendar=pd.DataFrame(formatted_events,columns=[\"start\",\"end\",\"event(currency)\",\"event_id\"])\n",
    "    # print(df_googlecalendar)\n",
    "    df_googlecalendar['len_date']=[len(df_googlecalendar.iloc[i]['start']) for i in range(len(df_googlecalendar))]\n",
    "    df_googlecalendar=df_googlecalendar[df_googlecalendar['len_date']==25]\n",
    "    df_googlecalendar['date']=[datetime_str[:4]+'/'+datetime_str[5:7]+'/'+datetime_str[8:10] for datetime_str in df_googlecalendar['start']]\n",
    "    df_googlecalendar['time']=[datetime_str[11:16] for datetime_str in df_googlecalendar['start']]\n",
    "    df_googlecalendar=df_googlecalendar.reindex(columns=['date','time','event(currency)','event_id'])\n",
    "    return df_googlecalendar\n",
    "\n",
    "# DataFrameのスケジュール情報をGoogle Calendarに追加\n",
    "def add_googlecalendar(calendar_id,service,df):\n",
    "    import datetime\n",
    "    \n",
    "    total=len(df['date'])\n",
    "    for i in range(total):\n",
    "    #    print(df_over4.iloc[i])\n",
    "        item=df.iloc[i]\n",
    "        print('全{}件中{}件完了\\n{}:({}){}をカレンダーに追加しています '.format(total,i,item['date'],item['currency'],item['event_short']))\n",
    "        body = {\n",
    "            'summary': '('+item['currency']+')'+item['event_short'],\n",
    "            'start': {\n",
    "                'dateTime':datetime.datetime.strptime(item['date']+' '+item['time'],'%Y/%m/%d %H:%M').isoformat(),\n",
    "                'timeZone':'Japan'\n",
    "            },\n",
    "            'end':{\n",
    "                'dateTime':(datetime.datetime.strptime(item['date']+' '+item['time'],'%Y/%m/%d %H:%M')+datetime.timedelta(minutes=5)).isoformat(),\n",
    "                'timeZone':'Japan'\n",
    "            }\n",
    "        }\n",
    "        event=service.events().insert(calendarId=calendar_id, body=body).execute()\n",
    "\n",
    "# DataFrameのスケジュール情報をGoogle Calendarから削除\n",
    "def remove_googlecalendar(calendar_id,service,df):\n",
    "    import datetime\n",
    "    import time\n",
    "    \n",
    "    total=len(df['date'])\n",
    "    for i in range(len(df)):\n",
    "        item=df.iloc[i]\n",
    "        print('全{}件中{}件完了\\n{}:{}を削除しています'.format(total,i,item['date'],item['event_short']))\n",
    "        service.events().delete(calendarId=calendar_id,eventId=df.iloc[i]['event_id']).execute()\n",
    "        time.sleep(3)  # サイトに拒否されないようにスリープを入れる\n",
    "        \n",
    "def initialize_googlecalendar():\n",
    "    import googleapiclient.discovery\n",
    "    import google.auth\n",
    "    SCOPES = ['https://www.googleapis.com/auth/calendar']\n",
    "    calendar_id = 'pk3dm4n2tmlqvr6t9h0ipeears@group.calendar.google.com'\n",
    "    gapi_creds = google.auth.load_credentials_from_file(r'D:\\FX\\★FX_chartfile\\MT4バッチツール\\googlecalendar\\mycalendarproject-374505-ded433e45278.json', SCOPES)[0]\n",
    "    service = googleapiclient.discovery.build('calendar', 'v3', credentials=gapi_creds)\n",
    "    return calendar_id, service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53cfbcf1-e411-4285-8040-a8d5943d7ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Googleカレンダーのイベント取得\n",
    "# import datetime\n",
    "# import googleapiclient.discovery\n",
    "# import google.auth\n",
    "\n",
    "# # 認証情報の設定\n",
    "# SCOPES = ['https://www.googleapis.com/auth/calendar.readonly']\n",
    "# SERVICE_ACCOUNT_FILE = r'D:\\FX\\★FX_chartfile\\MT4バッチツール\\googlecalendar\\mycalendarproject-374505-ded433e45278.json'\n",
    "\n",
    "# # 認証情報を読み込む\n",
    "# credentials = google.auth.load_credentials_from_file(SERVICE_ACCOUNT_FILE, SCOPES)[0]\n",
    "\n",
    "# # APIサービスを構築\n",
    "# service = googleapiclient.discovery.build('calendar', 'v3', credentials=credentials)\n",
    "\n",
    "# # 現在時刻を取得\n",
    "# #now = datetime.datetime.utcnow().isoformat() + 'Z'\n",
    "# now = \"T\".join(str(datetime.datetime.now(datetime.UTC)).split(\" \"))[:-6]+\"Z\"\n",
    "\n",
    "# # イベントを取得\n",
    "# events_result = service.events().list(\n",
    "#     calendarId='primary', timeMin=now,\n",
    "#     maxResults=50, singleEvents=True,\n",
    "#     orderBy='startTime').execute()\n",
    "# events = events_result.get('items', [])\n",
    "\n",
    "# # イベント情報を表示\n",
    "# if not events:\n",
    "#     print('No upcoming events found.')\n",
    "# for event in events:\n",
    "#     start = event['start'].get('dateTime', event['start'].get('date'))\n",
    "#     print(start, event['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df613daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250227のデータを取り込んでいます\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 重要なイベントだけ抽出\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mget_economiy_indicators_60days\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# df_over4=df[df['importance']>=4][df['currency']!='-']\u001b[39;00m\n\u001b[0;32m     10\u001b[0m df_over4\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimportance\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m&\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrency\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m, in \u001b[0;36mget_economiy_indicators_60days\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mのデータを取り込んでいます\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(date\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m---> 15\u001b[0m     df_temp\u001b[38;5;241m=\u001b[39m\u001b[43mget_economy_indicators_from_minkabu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mconcat([df,df_temp])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# date, country, event_shortが同一のデータを消去\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 149\u001b[0m, in \u001b[0;36mget_economy_indicators_from_minkabu\u001b[1;34m(date)\u001b[0m\n\u001b[0;32m    136\u001b[0m         priority\u001b[38;5;241m.\u001b[39mappend(priority_level)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m#        print('stars:{}'.format(priority_level))\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# DataFrame化\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# print(\"event:{},{}\".format(title,len(title)))\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;66;03m# print(\"event_short:{},{}\".format(short_title,len(short_title)))\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mdate_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtime_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimportance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mpriority\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcurrency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mcurrency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcountry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mcountry_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevent_short\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mshort_title\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# print(df)\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\jupyter\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\jupyter\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\jupyter\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\jupyter\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# google calendarに登録\n",
    "import datetime\n",
    "import googleapiclient.discovery\n",
    "import google.auth\n",
    "import pandas as pd\n",
    "\n",
    "# 重要なイベントだけ抽出\n",
    "df=get_economiy_indicators_60days()\n",
    "# df_over4=df[df['importance']>=4][df['currency']!='-']\n",
    "df_over4=df.loc[(df['importance']>=4)&(df['currency']!='-')]\n",
    "df_over4=pd.concat([df_over4,df.loc[(df['currency']=='CAD')&(df['event_short']=='中銀政策金利')]])\n",
    "df_over4['event(currency)']=['('+df_over4.iloc[i]['currency']+')'+df_over4.iloc[i]['event_short'] for i in range(len(df_over4))]\n",
    "\n",
    "# 現在のGoogleCalendarの情報を取得\n",
    "calendar_id,service=initialize_googlecalendar()\n",
    "googlecalendar=get_googlecalendar(calendar_id,service)\n",
    "\n",
    "# みんかぶの情報と現在のGoogle Calendarとの差分を抽出\n",
    "diff_df=pd.concat([googlecalendar,df_over4])\n",
    "diff_df.drop_duplicates(subset=['date','time','event(currency)'],keep=False,inplace=True)\n",
    "\n",
    "# そのうち、未登録の情報を追加\n",
    "add_df=diff_df[diff_df['event_id'].isnull()]\n",
    "add_googlecalendar(calendar_id,service,add_df)\n",
    "\n",
    "# そのうち、google calendarのみに存在する情報を消去\n",
    "del_df=diff_df[~diff_df['event_id'].isnull()]\n",
    "remove_googlecalendar(calendar_id,service,del_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80dfe37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 現時点のGoogle Calendarの登録内容を今日以降の登録内容をチェックし、重複しているイベントを削除\n",
    "def remove_duplicates_from_googlecalendar(calendar_id,service):\n",
    "    import datetime\n",
    "    import pandas as pd\n",
    "    import time\n",
    "\n",
    "#    now = (datetime.datetime.utcnow()-datetime.timedelta(days=5)).isoformat() + 'Z'  utcnow()が未推奨となったため変更\n",
    "    now = (datetime.datetime.now(datetime.UTC)-datetime.timedelta(days=5)).isoformat()[:-6] + \"Z\"\n",
    "\n",
    "    event_list = service.events().list(\n",
    "         calendarId=calendar_id, timeMin=now,\n",
    "    #     maxResults=3, \n",
    "         singleEvents=True,\n",
    "         orderBy='startTime').execute()\n",
    "\n",
    "    events = event_list.get('items', [])\n",
    "    formatted_events = [{'start':event['start'].get('dateTime', event['start'].get('date')), # start time or day\n",
    "         'end':event['end'].get('dateTime', event['end'].get('date')), # end time or day\n",
    "         'event':event['summary'],\n",
    "         'event_id':event['id']} for event in events]\n",
    "    df_googlecalendar=pd.DataFrame(formatted_events)\n",
    "    df_googlecalendar['duplicated']=df_googlecalendar.duplicated(subset=['start','end','event'])\n",
    "\n",
    "    j=0\n",
    "    for i in range(len(df_googlecalendar)):\n",
    "        if df_googlecalendar.iloc[i]['duplicated']==True:\n",
    "            j=j+1\n",
    "            item=df_googlecalendar.iloc[i]\n",
    "            print('{}:{}を削除しています'.format(item['start'],item['event']))\n",
    "            ret=service.events().delete(calendarId=calendar_id,eventId=item['event_id']).execute()\n",
    "            time.sleep(3)  # サイトに拒否されないようにスリープを入れる\n",
    "    print('{}件削除しました'.format(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "850d1776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0件削除しました\n"
     ]
    }
   ],
   "source": [
    "calendar_id,service=initialize_googlecalendar()\n",
    "remove_duplicates_from_googlecalendar(calendar_id,service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e82f0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
